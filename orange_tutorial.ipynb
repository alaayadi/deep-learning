{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnsit_tutorial.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2RvPErbdiizC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Networks"
      ]
    },
    {
      "metadata": {
        "id": "-9vy7PLliySf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Introduction\n",
        "In this practical we will cover the basics of convolutional neural networks, or \"ConvNets\". ConvNets were invented in the late 1980s/early 1990s, and have had tremendous success especially with vision (although they have also been used very successfully in speech processing pipelines, and more recently, for machine translation).\n",
        "\n",
        "\n",
        "# Learning Objectives\n",
        "* Be able to explain what a convolutional layer does and how it's different from a fully-connected layer \n",
        "* Understand  the assumptions and trade-offs that are being made when using convolutional architectures\n",
        "* Be able to build a convolutional architecture using Tensorflow and Keras Layers\n",
        "* Be able to use Keras to train a model on a dataset\n",
        "\n",
        "\n",
        "## Running on GPU\n",
        "For this practical, you will need to use a GPU to speed up training. To do this, go to the \"Runtime\" menu in Colab, select \"Change runtime type\" and then in the popup menu, choose \"GPU\" in the \"Hardware accelelator\" box. This is all you need to do, Colab and Tensorflow will take care of the rest! "
      ]
    },
    {
      "metadata": {
        "id": "jNnMKy4VkVVu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Convolutional Layers"
      ]
    },
    {
      "metadata": {
        "id": "iXjgPLBakQBA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A convolutional layer maps an input *volume* (meaning, a 3-D input tensor, e.g. [width, height, channels]) to an output volume through a set of learnable filters, which make up the parameters of the layer. Every filter is small spatially (along width and height), but extends through the full depth of the input volume. (Eg: A filter in the first layer of a ConvNet might have size [5, 5, 3]). During the forward pass, we convolve (\"slide\") each filter across the width and height of the input volume and compute element-wise dot products between the entries of the filter and the input at any position. As we slide the filter over the width and height of the input volume we will produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. Each convolutional layer will have such a set of filters, and each of them will produce a separate 2-dimensional activation map. We then stack these activation maps along the depth-dimension to produce the output volume.\n",
        "\n",
        "By using these filters which map to a small sub-volume of the input, we can to a large extent,control the parameter explosion that we would get with a (fully-connected) feed-forward network. This **parameter sharing** actually also tends to improve the performance of the model on inputs like natural images because it provides the model with some limited **translation invariance**. Translation invariance means that if the image (or a feature in the image) is translated (moved), the model will not be significantly affected. Think about why this is the case!\n",
        "\n",
        "The following animation illustrates these ideas, make sure you understand them!\n",
        "\n",
        "![Convolution Animation](https://i.stack.imgur.com/FjvuN.gif)"
      ]
    },
    {
      "metadata": {
        "id": "J_GnLthwkhMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The hyper-parameters of a convolutional layer are as follows:\n",
        "* **Filters** defines the number of filters in the layer\n",
        "* **Kernel Size** defines the width and height of the filters (also called \"kernels\") in the layer. Note that kernels always have the same depth as the inputs to the layer.\n",
        "* **Stride** defines the number of pixels by which we move the filter when \"sliding\" it along the input volume. Typically this value would be 1, but values of 2 and 3 are also sometimes used.\n",
        "* **Padding** refers to the addition of 0-value pixels to the edges of the input volume along the width and height dimensions. In Tensorflow you can set this to \"VALID\", which essentially does no padding or \"SAME\" which pads the input such that the output width and height are the same as the input.\n",
        "\n",
        "Lets look at a very simple, dummy example to see how the values of the hyper-parameters affect the output size of a convolutional layer."
      ]
    },
    {
      "metadata": {
        "id": "nVD_eQHyb9X1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** the needed packages**"
      ]
    },
    {
      "metadata": {
        "id": "cjLBfGq449Vf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItF3_IrZdsVK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data collection**"
      ]
    },
    {
      "metadata": {
        "id": "i6oo0Dr1STCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist #28*28 image of handwritten of 0-9 \n",
        "(x_train, y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMyZs5aUWNp9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test = np.array(y_test.reshape((-1,1)) )\n",
        "y_train = np.array(y_train.reshape((-1,1)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWkU36r-OpvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train.reshape((-1,28, 28,1)) )\n",
        "x_test= np.array(x_test.reshape((-1,28, 28,1)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51gWMWV8U0v2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Training Data Shape is {}\".format(x_train.shape))\n",
        "print(\"Training Labels Shape is {}\".format(y_train.shape))\n",
        "print(\"Testing Data Shape is {}\".format(x_test.shape))\n",
        "print(\"Testing Labels Shape is {}\".format(y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HiHbQF0LUs-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Sample Training label is {}\".format(y_train[0:5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RgMo0SNVEzV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_train[5].reshape(28, 28))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YYISenNcd0Io",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prepering the image data**"
      ]
    },
    {
      "metadata": {
        "id": "JeMHNaPLUrRm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train/255.\n",
        "x_test = x_test/255."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QC6iVuk2UgHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Training Data after normalizing is {}\".format(x_train[0].reshape(28, 28)))\n",
        "print(\"Testing  Data after normalizing is {}\".format(x_test[0].reshape(28, 28)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWIs89KTWlh0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Conv2D(32,(3,3),activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64,(3,3), activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(128,(3,3), activation=tf.nn.relu),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iHFfieiyPYUW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8emPzbVKd5Mn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Training model**"
      ]
    },
    {
      "metadata": {
        "id": "RCIlxn95RZj0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Di2Sn4ZdeLhw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**predict on the test data**"
      ]
    },
    {
      "metadata": {
        "id": "C_vay4adQa8P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Validation accuracy: ', test_acc)\n",
        "print('    Validation loss: ', test_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_s3phtsIV0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict([x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IvfQVcuWSewk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Probability distribution for a multi-class classification\")\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GLNwMw2YgSO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMzJJrGCYrf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[0].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8EUA3M_SoCF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
        "print(val_loss, val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dhh9W4N-SwFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict([x_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rscobu5vS35U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(np.argmax(predictions[4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_t4-R7phS8kB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(x_test[4].reshape(28, 28), cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoYIgCIOY-os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvpKkDQ8Y-qq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be+ thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vy-aBLhbrFZH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "user_test = filename\n",
        "col = Image.open(user_test)\n",
        "gray = col.convert('L')\n",
        "bw = gray.point(lambda x: 0 if x<100 else 255, '1')\n",
        "bw.save(\"bw_image.jpg\")\n",
        "bw\n",
        "img_array = cv2.imread(\"bw_image.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "img_array = cv2.bitwise_not(img_array)\n",
        "print(img_array.size)\n",
        "plt.imshow(img_array, cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "img_size = 28\n",
        "new_array = cv2.resize(img_array, (img_size,img_size))\n",
        "plt.imshow(new_array, cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "user_test = tf.keras.utils.normalize(new_array, axis = 1)\n",
        "user_test = np.array(user_test.reshape((28, 28,1)) )\n",
        "\n",
        "predicted = model.predict([[user_test]])\n",
        "a = predicted[0][0]\n",
        "for i in range(0,10):\n",
        "  b = predicted[0][i]\n",
        "  print(\"Probability Distribution for\",i,b)\n",
        "\n",
        "print(\"The Predicted Value is\",np.argmax(predicted[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sjjtGv0DVSej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Additional Resources\n",
        "\n",
        "Here's some more information on ConvNets:\n",
        "\n",
        "* Chris Colah's blog post on [Understanding Convolutions](https://colah.github.io/posts/2014-07-Understanding-Convolutions/)\n",
        "* [How do convolutional neural networks work?](http://brohrer.github.io/how_convolutional_neural_networks_work.html)\n",
        "* The [CS231n course](https://cs231n.github.io/)\n",
        "* [Building blocks of interpretability](https://distill.pub/2018/building-blocks/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "e06xE0IxVWta",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}